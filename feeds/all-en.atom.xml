<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Blog of Bernardas AliÅ¡auskas</title><link href="https://granitosaurus.github.io/" rel="alternate"></link><link href="https://granitosaurus.github.io/feeds/all-en.atom.xml" rel="self"></link><id>https://granitosaurus.github.io/</id><updated>2017-01-18T00:00:00+01:00</updated><entry><title>My bin: center</title><link href="https://granitosaurus.github.io/my-bin-center.html" rel="alternate"></link><published>2017-01-18T00:00:00+01:00</published><updated>2017-01-18T00:00:00+01:00</updated><author><name>Bernardas AliÅ¡auskas</name></author><id>tag:granitosaurus.github.io,2017-01-18:/my-bin-center.html</id><summary type="html">&lt;p&gt;Some of the useful things I have in my ~/bin&lt;/p&gt;</summary><content type="html">&lt;p&gt;People are naturally lazy and strive to automate as much as possible. I'm no exception and my user scripts directory &lt;code&gt;~/bin&lt;/code&gt; is full of scripts that make my life easier or at least makes me feel that way.  &lt;/p&gt;
&lt;p&gt;Today I want to show you and explain some bits of a little python script for centering text. It's isn't particularly special, but it's a great base to show of how awesome and powerful python command line tools can be!&lt;br&gt;
It's a simple pipeable script that takes in some text, centers it according to your terminal size and outputs it to standard output.My use case for this is for reading poems and by default they are not centered properly. To add to that I also like to constantly resize my terminal window because I'm running &lt;a href="http://i3wm.org/"&gt;i3wm&lt;/a&gt; - a tilling windows manager for linux, which forces every window to use up all of the space it can, which makes them very much dynamic and unpredictable.&lt;/p&gt;
&lt;p&gt;In other words it turns something like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ cat raven.md
Once upon a midnight dreary, &lt;span class="k"&gt;while&lt;/span&gt; I pondered, weak and weary,
Over many a quaint and curious volume of forgotten lore,
While I nodded, nearly napping, suddenly there came a tapping,
As of some one gently rapping, rapping at my chamber door.
&lt;span class="s1"&gt;&amp;#39;Tis some visitor,&amp;#39;&lt;/span&gt; I muttered, &lt;span class="s1"&gt;&amp;#39;tapping at my chamber door-&lt;/span&gt;
&lt;span class="s1"&gt;Only this, and nothing more.&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Into:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ cat raven.md &lt;span class="p"&gt;|&lt;/span&gt; center
             Once upon a midnight dreary, &lt;span class="k"&gt;while&lt;/span&gt; I pondered, weak and weary,              
                Over many a quaint and curious volume of forgotten lore,                 
             While I nodded, nearly napping, suddenly there came a tapping,              
               As of some one gently rapping, rapping at my chamber door.                
              &lt;span class="s1"&gt;&amp;#39;Tis some visitor,&amp;#39;&lt;/span&gt; I muttered, &lt;span class="s1"&gt;&amp;#39;tapping at my chamber door-               &lt;/span&gt;
&lt;span class="s1"&gt;                              Only this, and nothing more.&amp;#39;&lt;/span&gt;   
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;While taking your current terminal size into account, so no matter what you're doing or where you are the text will nice and pretty.   &lt;/p&gt;
&lt;h3&gt;Source&lt;/h3&gt;
&lt;p&gt;Now lets take a look at the source code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="c1"&gt;#!/usr/bin/env python3&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;click&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;shutil&lt;/span&gt;


    &lt;span class="nd"&gt;@click.command&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="nd"&gt;@click.argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;input&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;required&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;File&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="nd"&gt;@click.argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;output&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;required&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;File&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="nd"&gt;@click.option&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;-l&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;--length&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;maximum line length [default:current terminal size]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;click&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;INT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cli&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Simple, pipeable tool for centering text&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shutil&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_terminal_size&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;  &lt;span class="c1"&gt;#1&lt;/span&gt;
        &lt;span class="n"&gt;source&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdin&lt;/span&gt;  &lt;span class="c1"&gt;#2&lt;/span&gt;
        &lt;span class="n"&gt;_format&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{{:^{}}}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c1"&gt;#3&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="c1"&gt;#4&lt;/span&gt;
            &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_format&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;cli&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Explanation&lt;/h3&gt;
&lt;p&gt;I love &lt;code&gt;click&lt;/code&gt; library, which is a tool for creating command line interfaces. It's beautiful, easy and saves so much space and time. So we start off with two positional arguments for input and output filenames, these are not necessary for pipe logic we need but is a nice addition if there's a need for standalone function and only takes two extra lines, so why not!  &lt;br&gt;
Next we have custom option for length which allows overriding maximum line length. In case you have a very huge terminal window and you just want a nice margin instead of the text being at the very center of your screen.
Finally there's the program itself:&lt;br&gt;
&lt;code&gt;#1&lt;/code&gt; - We retrieve dimensions of the current terminal window. This returns a tuple of &lt;code&gt;(columns, rows)&lt;/code&gt; since we only care about columns we take the first member.&lt;br&gt;
&lt;code&gt;#2&lt;/code&gt; - We decide on which source to use for input, if first position argument is supplied to script, we'll use that as a source, otherwise use standard input.&lt;br&gt;
&lt;code&gt;#3&lt;/code&gt; - This might appear complicated but what we are doing here is creating a format that we will use to format every line of our text. The line evaluates to &lt;code&gt;{:^&amp;lt;terminal_size&amp;gt;}\n&lt;/code&gt; now if we call &lt;code&gt;.format()&lt;/code&gt; on that we can insert text and it will be centered. For more check out &lt;a href="https://docs.python.org/3.1/library/string.html#string-formatting"&gt;python's string formatting&lt;/a&gt;, it's awesome!&lt;br&gt;
&lt;code&gt;#4&lt;/code&gt; - And lastly we have the loop itself. Here we loop through every line, center it and either write it to file if the second positional argument is supplied or put it straight to standard output.  &lt;/p&gt;
&lt;h3&gt;Improvements&lt;/h3&gt;
&lt;p&gt;You could probably go wild with bunch of flags and modifications but it's important to remember to KISS - keep it simple stupid. With pipes, aliases and various other shortcuts leaving this script to do one job is very much a good idea! :) &lt;/p&gt;
&lt;h3&gt;Pitfalls&lt;/h3&gt;
&lt;p&gt;One of the pitfalls I've experience with piping in python scripts is when piping to &lt;code&gt;less&lt;/code&gt; or similar tools. &lt;br&gt;
Because of how &lt;code&gt;shutils.get_terminal_size()&lt;/code&gt; works, if a parameter &lt;code&gt;fallback&lt;/code&gt; is set, like: &lt;code&gt;shutils.get_terminal_size(fallback=(80,30))&lt;/code&gt; the set fallback will actually be used instead of your terminal size if piped to &lt;code&gt;less&lt;/code&gt; or similar tool.&lt;br&gt;
I'm not certain why it behaves like that, my guess being is that &lt;code&gt;less&lt;/code&gt; breaks the terminal size function, but opposed to general recommendations of setting a fallback it's best to not set it in this case.&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;I'd like to encourage anyone who use ugly awk scripts and aliases just write a short command line application with click, it takes no longer than 10 minutes, is beautiful, usable, readable and easily shareable. Let me know if you have any questions and stay tuned for more scripts and explanations!&lt;/p&gt;</content><category term="python"></category><category term="linux"></category><category term="guide"></category><category term="my-bin"></category></entry><entry><title>Using python to setup desktop notifications.</title><link href="https://granitosaurus.github.io/notify-send.html" rel="alternate"></link><published>2016-11-03T10:20:00+01:00</published><updated>2016-11-03T10:20:00+01:00</updated><author><name>Bernardas AliÅ¡auskas</name></author><id>tag:granitosaurus.github.io,2016-11-03:/notify-send.html</id><summary type="html">&lt;p&gt;Notify-send is great, you should use it!&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Notifications On Linux&lt;/h1&gt;
&lt;p&gt;Most gnu/linux systems use &lt;code&gt;libnotify&lt;/code&gt; package for notifications - this package provides simple &lt;code&gt;notify-send&lt;/code&gt; command line interface for sending notifications to your desktop environment or directly to your xorg display.&lt;br&gt;
To use it however, you need a running daemon program that handles all this; my personal recommendation is &lt;code&gt;dunst&lt;/code&gt;. You can find more info about this and alternatives to &lt;code&gt;dunst&lt;/code&gt; in this arch-wiki &lt;a href="https://wiki.archlinux.org/index.php/Desktop_notifications#Standalone"&gt;article&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Python and notifications.&lt;/h1&gt;
&lt;p&gt;Python is a perfect language for making notifications like this!&lt;br&gt;
By default python comes with everything we need to set this up, however to make things nicer lets use &lt;code&gt;click&lt;/code&gt; command line interface package. It will greatly simplify the cli part of the program. You can get it from pip via &lt;code&gt;pip install click&lt;/code&gt; and skim through the &lt;a href="http://click.pocoo.org/"&gt;tutorial here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All you need to send the notification with python:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;subprocess.call([&amp;#39;notify-send&amp;#39;, &amp;#39;title&amp;#39;, &amp;#39;body&amp;#39;])
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we can use this to make a real application!&lt;/p&gt;
&lt;h3&gt;Bonus: Setup Notifications&lt;/h3&gt;
&lt;p&gt;By default majority of gnu/linux distributions already have everything covered for you! &lt;code&gt;libnotify&lt;/code&gt; should be installed and some sort of notification daemon should be running in the background.&lt;br&gt;
Try writing this in your terminal:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;notify-send &amp;quot;test title&amp;quot; &amp;quot;test body&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you see something, then great - you're done with this step!  &lt;/p&gt;
&lt;p&gt;Otherwise you're probably missing a notification daemon. To fix that you need to install one, let's go with &lt;a href="http://knopwob.org/dunst/index.html"&gt;dunst&lt;/a&gt;.&lt;br&gt;
You can simply pull it from you package manager, e.g.:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo pacman -S dunst  # for arch
sudo apt install dunst  # for ubuntu
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Usually &lt;code&gt;dunst&lt;/code&gt; autostarts on majority of system on boot up as DBus autostarts it by default, but some systems might require explicit autostart, so in your init file just call &lt;code&gt;dunst&lt;/code&gt;, e.g. for i3wm you'd add &lt;code&gt;exec dunst&lt;/code&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="dunst solarized" src="{filename}/images/dunst.png"&gt;
You can also customize your dunst quite extensively as well. All you need to do is pass the location of the config file as &lt;code&gt;--conf&lt;/code&gt; parameter, i.e. &lt;code&gt;dunst --config ~/.dunstrc&lt;/code&gt;.&lt;br&gt;
I'm running solarized look and you can find my config &lt;a href="https://github.com/Granitosaurus/.dotfiles/.dunstrc"&gt;on my dotfiles repo here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dunst is also keyboard driven which means you can:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# Close notifactions
close = ctrl+space
close_all = ctrl+shift+space
# Show history of notifications
history = ctrl+grave
# Open context of the notification
# e.g. if notification has an url - open it in default browser
context = ctrl+shift+period
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It's really lovely and I highly recommend choosing dunst as your notification-daemon!&lt;/p&gt;</content><category term="python"></category><category term="linux"></category><category term="guide"></category></entry><entry><title>How to get scrapy help.</title><link href="https://granitosaurus.github.io/scrapy-help.html" rel="alternate"></link><published>2016-10-30T00:00:00+02:00</published><updated>2016-10-30T00:00:00+02:00</updated><author><name>Bernardas AliÅ¡auskas</name></author><id>tag:granitosaurus.github.io,2016-10-30:/scrapy-help.html</id><summary type="html">&lt;p&gt;Few suggestions how to ask questions correctly and where to ask them regarding using scrapy web-crawling framework.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Scrapy is a web-scraping framework for python. It's pretty popular and at the moment of writing it has over 16000 stars &lt;a href="https://github.com/scrapy/scrapy"&gt;on github&lt;/a&gt;. In terms of codebase scrapy is pretty simple, however there are few things that are not as explicit as they could be in favor of abstraction and development simplicity.&lt;br&gt;
Not to mention millions of websites that provide their own unique scraping challenges.  &lt;/p&gt;
&lt;p&gt;So if you do end up not understanding something or encountering some of the few scrapy's quirks, how do you go about it?&lt;/p&gt;
&lt;h1&gt;Stackoverflow Guidelines&lt;/h1&gt;
&lt;p&gt;First thing you should do is read is &lt;a href="http://stackoverflow.com/help/how-to-ask"&gt;&lt;em&gt;how to ask a good question on stackoverflow&lt;/em&gt;&lt;/a&gt;. &lt;br&gt;
It's a brilliant guide by, without a doubt the biggest Q&amp;amp;A website on the web, and it focuses on how to ask a good questions regardless of the topic. Following these guidelines not only make it easy for people to help you but also easy for you, yourself to formulate your question and understand the issue you are facing!&lt;/p&gt;
&lt;h1&gt;Where To Get Help?&lt;/h1&gt;
&lt;p&gt;There are two places you can go to with your scrapy related questions and issues:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://stackoverflow.com/questions/tagged/scrapy"&gt;Stackoverflow&lt;/a&gt;. &lt;br&gt;
The issue with Stackoverflow is that it has a general rule of questions having to be generic, that means asking how to get price on this item on amazon is not a fit question. However the user base on &lt;code&gt;scrapy&lt;/code&gt; tag seems to be quite understanding of this and tend to be quite lenient with reports and down-votes, but don't be surprised if your post gets down-voted or put on hold. All you can do is to try and make your issue more generic and hope for the best!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;IRC! @ irc.freenode.org #scrapy &lt;br&gt;
Good old IRC has been there for decades and even though it dropped in popularity quite significantly, it's still a great place to get help on any subject and scrapy is not an exception. 
Feel free to join the channel and ask questions about anything scrapy related; you can find me there too!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://support.scrapinghub.com/forums/1-general/"&gt;Scrapinghub Forums&lt;/a&gt;&lt;br&gt;
Scrapinghub is the company behind scrapy and they have a user forum, so naturally it's a great place to look for help when it comes to your scrapy issues!  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reddit&lt;br&gt;
There's an official &lt;a href="https://reddit.com/r/scrapy"&gt;scrapy subreddit&lt;/a&gt;, which isn't very active but I can tell you for a fact that a lot of people that are involved with scrapy keep an eye on it. It's a great place for some discussions that might not fit stackoverflow and irc.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Providing Information&lt;/h1&gt;
&lt;p&gt;To debug an issue and get the help you need you need to provide information about your problem:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Source Code of your spider, settings.py and pipelines.py files.&lt;/li&gt;
&lt;li&gt;Website you are crawling - sometimes people refrain from providing the url in fear of legal issues or some judgment. Don't worry about that, scraping is very much legal and no one will judge you, it might very well be the opposite - people might be more keen to help you scrape some weird porn website than amazon.  &lt;/li&gt;
&lt;li&gt;Crawl Log (see &lt;a href="#log"&gt;Producing Logs&lt;/a&gt;) - Scrapy logs majority of the events that happen in your spider, so to debug your spider the best resources are these logs.  &lt;/li&gt;
&lt;li&gt;Spider Output (see &lt;a href="#output"&gt;Producing Output&lt;/a&gt;) - This will rarely be useful for anyone else but yourself, but it can be very useful in some cases.  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once you have these bits you can easily formulate your question and I'm sure someone will help you out!&lt;/p&gt;
&lt;h2 id="log"&gt;Producing Logs&lt;/h2&gt;
&lt;p&gt;To save a log of your spider run you can use UNIX output redirection syntax:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scrapy crawl myspider 2&amp;gt;&amp;amp;1 &amp;gt; mylog.log
# or
scrapy crawl myspider &amp;amp;&amp;gt; mylog.log
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Explanation:&lt;br&gt;
    1. &lt;code&gt;scrapy crawl myspider&lt;/code&gt; - is a scrapy command that will start crawling spider called &lt;code&gt;myspider&lt;/code&gt;&lt;br&gt;
    2. &lt;code&gt;2&amp;gt;&amp;amp;1&lt;/code&gt; - is UNIX syntax for redirecting error output to standard output. In UNIX there are types of outputs and in your log you want to have both of them in one file.&lt;br&gt;
    3. &lt;code&gt;&amp;gt; mylog.log&lt;/code&gt; - is another UNIX output redirection, but this time we redirect the output to file called &lt;code&gt;mylog.log&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Tip: points 2 and 3 can be summarized as &lt;code&gt;&amp;amp;&amp;gt;&lt;/code&gt; in bash version 4 and up&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For logging scrapy uses python's built-in &lt;a href="https://docs.python.org/3/library/logging.html"&gt;&lt;code&gt;logging&lt;/code&gt; module&lt;/a&gt; which by itself is pretty awesome! If you look into it, it might appear quite daunting but you can actually just &lt;code&gt;import logging&lt;/code&gt; and simply log message to root logger: &lt;code&gt;logging.warning("this page has no next page")&lt;/code&gt;. To have simple logging in your spider.&lt;/p&gt;
&lt;h2 id="output"&gt;Producing Output&lt;/h2&gt;
&lt;p&gt;Scrapy can automatically produce output in one these formats:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;#39;xml&amp;#39;, &amp;#39;jsonlines&amp;#39;, &amp;#39;jl&amp;#39;, &amp;#39;json&amp;#39;, &amp;#39;csv&amp;#39;, &amp;#39;pickle&amp;#39;, &amp;#39;marshal&amp;#39;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To do that simply run &lt;code&gt;crawl&lt;/code&gt; command with &lt;code&gt;--output&lt;/code&gt; flag (&lt;code&gt;-o&lt;/code&gt; for short version) and provide a name + file ending of format you want as an argument:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scrapy crawl myspider --output output.json
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;em&gt;This will output all items your spider spews out to &lt;code&gt;output.json&lt;/code&gt; file.&lt;/em&gt;  &lt;/p&gt;
&lt;p&gt;To get help for readability purposes you probably want to use either &lt;code&gt;json&lt;/code&gt; or &lt;code&gt;xml&lt;/code&gt; since those are most readable and as described in section below parsing-friendly formats.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Tip: You can actually tell scrapy to produce output to stdout directly by setting output argument to &lt;code&gt;-&lt;/code&gt;:&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scrapy crawl myspider -t json -o - output.json
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Inspecting Output&lt;/h2&gt;
&lt;p&gt;There few tools to parse &lt;code&gt;json&lt;/code&gt; or &lt;code&gt;xml&lt;/code&gt; content, similar like you'd use &lt;code&gt;sed&lt;/code&gt; or &lt;code&gt;grep&lt;/code&gt; in unix. The most popular and widely known is probably &lt;a href="https://stedolan.github.io/jq/"&gt;jq&lt;/a&gt;, which I believe translates to json query.&lt;br&gt;
I personally really dislike that jq uses it's own mini-language as opposed to xpath or css selectors we all know, love and use daily.&lt;br&gt;
So in response to this I made &lt;a href="https://github.com/granitosaurus/pq/"&gt;&lt;strong&gt;PQ&lt;/strong&gt;&lt;/a&gt;! It uses xpath and css selectors as well as support both json and xml parsing.&lt;/p&gt;
&lt;p&gt;To put it shortly, using the tools described above you can find specific values of some fields really easily.&lt;br&gt;
Lets imagine we have a bunch of products that have these fields: name and price. Now for some reason Samsung items have weird pricing and we want to find out whether that's the case every time we update the code. &lt;/p&gt;
&lt;p&gt;For example using pq we can navigate the prices of items that have some keywords in their names:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cat output.json | pq &amp;quot;//item[contains(@name,&amp;#39;samsung&amp;#39;)]/price/text()&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Will find all items that contain "samsung" in the name and output their price values. If you change up your spider an run this command again you can easily navigate whether the values are changing.&lt;/p&gt;
&lt;p&gt;You can combine this with scrapy spider redirection to have everything in one line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scrapy crawl spider --nolog -t json -o - | pq &amp;quot;//item[contains(@name,&amp;#39;samsung&amp;#39;)]/price/text()&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Scrapy is a lovely framework and web-crawling is a tricky subjects with a lot of hidden issues, quirks and complexities. Because of it being rather big subjects and every spider having it's own challenges it might be difficult to find help. However I feel if you follow the steps and ideas described in this blog post you'll have a really good chance at getting some help either on stackoverflow or irc!&lt;/p&gt;
&lt;p&gt;Do you have any places where you go to with your scrapy or web-crawling related questions? Did I miss something important? Leave the comment below :)&lt;/p&gt;</content><category term="scrapy"></category><category term="python"></category><category term="stackoverflow"></category><category term="web-crawling"></category></entry><entry><title>Pycon PL + Warsaw report</title><link href="https://granitosaurus.github.io/pycon-pl-after.html" rel="alternate"></link><published>2016-10-23T00:00:00+02:00</published><updated>2016-10-23T00:00:00+02:00</updated><author><name>Bernardas AliÅ¡auskas</name></author><id>tag:granitosaurus.github.io,2016-10-23:/pycon-pl-after.html</id><summary type="html">&lt;p&gt;Pycon Poland and Warsaw aftermath: a summary of my experience in Pycon Poland and Poland, Warsaw in general.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last year during Euro-Python 2015 someone from PyconPL had an interesting lightning talk about PyconPL, and since that moment I was sold. However I missed it by few days that year. However this year I made it and as a bonus I checked out Warsaw, Poland too!&lt;/p&gt;
&lt;p&gt;You can check my previous blog post how we got to Warsaw &lt;a href="/pycon-pl.html"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Before going to Pycon me and my girlfriend took two days to look around Warsaw, Poland. Throughout the trip we stayed in 3 airbnb places. The first day we were really surprised how pretty and big Warsaw is. To give a little background, before the trip we did a bunch of research of what to do in Warsaw and we really didn't find much so we didn't have high hopes to begin with, thus the surprise. &lt;/p&gt;
&lt;p&gt;So without further ado, here is what I (and in some cases we) think of Warsaw!&lt;/p&gt;
&lt;h2&gt;Food and Prices&lt;/h2&gt;
&lt;p&gt;The city is beautiful and there are so &lt;strong&gt;many restaurants and cafes&lt;/strong&gt;. The first thing we did was go to &lt;a href="https://www.tripadvisor.com/Restaurant_Review-g274856-d8529497-Reviews-Mango_Vegan_Street_Food-Warsaw_Mazovia_Province_Central_Poland.html"&gt;Mango Vegan Street Food&lt;/a&gt; which serves great hummus as well as other vegan dishes at a surprisingly low price, brilliant little place!   &lt;/p&gt;
&lt;p&gt;Low price is definitely a recurring theme in Warsaw - everything is surprisingly cheaper than in Estonia or Lithuania.&lt;br&gt;
I've heard of a saying: "Poland is an eastern-european country with western-european prices" which I heavily disagree with, unless western-europe is cheaper than eastern in this context. Everything in general is at least 20% cheaper than in Estonia, sometimes significantly more and quality doesn't suffer because of it. The selection of foods and products in general is huge too - one of the benefits of being in central Europe I guess.&lt;/p&gt;
&lt;p&gt;As a vegetarian I was surprised by how &lt;strong&gt;many vegetarian places&lt;/strong&gt; and options there are in Warsaw. The vegan trend definitely feels real, which was both a pleasant surprise and a piece of convenience for myself.  &lt;/p&gt;
&lt;blockquote&gt;
&lt;dl&gt;
&lt;dt&gt;Simple Definition of meat&lt;/dt&gt;
&lt;dd&gt;the flesh of an animal used as food&lt;/dd&gt;
&lt;dd&gt;a type of meat&lt;/dd&gt;
&lt;dd&gt;the part of something (such as a nut) that can be eaten&lt;/dd&gt;
&lt;/dl&gt;
&lt;/blockquote&gt;
&lt;p&gt;As a side note for vegetarianism itself - I found that a lot of polish people do not consider fish to be meat, which is extremely weird and nonsensical. I've noticed that it's a quite common misunderstanding across Europe and had a very similar thing happen in Spain during my visit for Europython 2015 when the vegetarian sandwich I ordered contained tuna...&lt;/p&gt;
&lt;p&gt;Also worth noting that a &lt;strong&gt;vegetarian person who eats fish is actually called pescatarian&lt;/strong&gt;. It's a rather peculiar sounding term but it's there for a reason.&lt;/p&gt;
&lt;h3&gt;Rurki&lt;/h3&gt;
&lt;p&gt;&lt;img alt="rurki" src="https://granitosaurus.github.io/images/rurki.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;There are few traditional Polish dishes, but as someone who's from eastern europe himself, I didn't find them unique or interesting at all. All except one: Rurki.&lt;br&gt;
Rurki is a waffle roll with sweet cream inside of it. It's pretty simple but boy it's delicious! It's sweet, crunchy and creamy at the same time - a perfect dessert!&lt;br&gt;
The best rurki we've eat were located in &lt;a href="https://www.tripadvisor.com/Attraction_Review-g274856-d2235946-Reviews-Zlote_Tarasy-Warsaw_Mazovia_Province_Central_Poland.html"&gt;&lt;strong&gt;Zloty Tarasy&lt;/strong&gt;&lt;/a&gt; shopping mall. At the very bottom floor there is a small sweets kiosk that offers the best rurki in the city!&lt;/p&gt;
&lt;h3&gt;Few Cool Food Joints&lt;/h3&gt;
&lt;p&gt;There wasn't that much to do in Warsaw, at least during our trip, so we ate out a lot. Here's a short list of my favourite places, that I highly recommend!&lt;/p&gt;
&lt;h4&gt;&lt;a href="https://www.tripadvisor.com/Restaurant_Review-g274856-d8529497-Reviews-Mango_Vegan_Street_Food-Warsaw_Mazovia_Province_Central_Poland.html"&gt;Mango Vegan Street Food&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;img alt="mango vegan street food" src="https://media-cdn.tripadvisor.com/media/photo-s/09/c0/d2/6d/mango-vegan-street-food.jpg"&gt;&lt;br&gt;
As I've mentioned above the place is great. It's quite cheap and the food is great. You can get daily deals (that last whole day) and some weekdays have discounts on some dishes. The food selection isn't great, mostly it's just flavours and variants of few dishes, but it's enough for few visits a week. A great place for a quick snack or a lengthier sit down! &lt;br&gt;
Personal favourite and highly recommended: Pomegranate Hummus!  &lt;/p&gt;
&lt;h4&gt;&lt;a href="https://www.tripadvisor.com/Restaurant_Review-g274856-d7189289-Reviews-Bubbleology-Warsaw_Mazovia_Province_Central_Poland.html"&gt;Bubbleology&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;img alt="bubbleology" src="https://instagram.fhen1-1.fna.fbcdn.net/t51.2885-15/e35/14711881_1261966857193875_5168882141601202176_n.jpg"&gt;&lt;br&gt;
Bubble tea used to be a pretty huge fad across the whole Europe few years ago. However these days it's no longer even a thing in Estonia or Lithuania. Bubble tea is a tea drink with syrup-like bubbles that you can suck in using bigger than usual straw, it's a mix of a dessert and a drink which seems to be the strategy of the biggest cafe brand Starbucks, so we know it works!  &lt;br&gt;
There's nothing particularity interesting about this shop other than it's themed as a science lab where bubble tea science happens. They really go all out by even dressing the clerks in lab coats and devising made up bubble tea formulas on the walls.  &lt;/p&gt;
&lt;p&gt;Regarding the prices - they are somewhat steeper than you'd expect even when Bubble tea in general is considered to be more expensive than it should. 
It wasn't the best bubble tea I had but it was good nevertheless so if you miss bubble tea or even worse - never tried it - check this place out!  &lt;/p&gt;
&lt;h4&gt;&lt;a href="https://www.yelp.com/biz/mins-onigiri-warszawa?osq=onigiri"&gt;Min's Onigiri&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;img alt="min's onigiri place" src="https://instagram.fhen1-1.fna.fbcdn.net/t51.2885-15/e35/14718290_983459391766489_1937566249529638912_n.jpg"&gt;&lt;br&gt;
&lt;em&gt;Onigiri&lt;/em&gt; is a Japanese rice ball that can be can contain some flavouring in the middle of it and topped of with dry seaweed wrapping. Historically it was invented as food for travelers, so it's a perfect food for tourists!&lt;br&gt;
I really enjoyed this place, it only serves around 8 kinds of different rice balls and only 3 of them were vegetarian friendly, but all 3 of them were delicious. It also serves miso soup which is more or less bullion alternative Japanese use.&lt;br&gt;
The onigiri themselves aren't that big, so you most likely want to take several. They are extremely delicious however and the miso + onigiri combo ended up being a perfect autumn food for tourists!  &lt;/p&gt;
&lt;p&gt;Regarding the prices - it's really reasonable. One rice ball + miso soup ended up being 10 PLN (2.3 euros) and 7 without the soup.  &lt;/p&gt;
&lt;h4&gt;&lt;a href="https://www.tripadvisor.com/Restaurant_Review-g274856-d2619568-Reviews-Tel_Aviv_Food_Wine-Warsaw_Mazovia_Province_Central_Poland.html"&gt;Tel Aviv Food &amp;amp; Wine&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;img alt="tel aviv restaurant during summer" src="https://s3-media4.fl.yelpcdn.com/bphoto/oGNq8N4egk1fMxpk672_TQ/o.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;Another vegan place, this time though, it's a quite fancy one. The place itself is pretty close to the center and easy to reach, however it's pretty small so you should avoid going there during peak hours.&lt;br&gt;
The food is very fancy, but personally I wasn't impressed - it was very pretty but didn't have taste or price value to match it. I think I would reserve this place for more fancy occasions rather than a lunch break or a meet up.&lt;/p&gt;
&lt;h4&gt;&lt;a href="http://www.greencaffenero.pl/en/"&gt;Green Caffe Nero&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;There really isn't much to say about this place. It's a rather regular cafÃ©, but it's really &lt;strong&gt;affordable&lt;/strong&gt;, has decent food, tea and coffee, and most importantly it's &lt;strong&gt;quite cozy&lt;/strong&gt; - so it's perfect for tourist stop for a tired, cold and worn-out tourist as myself!&lt;br&gt;
Sitting down with a cup of hot tea, almost italian sandwich and writing some code or a blog for half an hour is always a pleasant experience, wherever you are.&lt;/p&gt;
&lt;p&gt;You can find them pretty much on every corner, sometimes you can even see another one from sitting inside one yourself :D&lt;/p&gt;
&lt;h3&gt;Few Cool Places&lt;/h3&gt;
&lt;p&gt;Before we left to Poland we did some research of what to visit but couldn't find much other than war museums that are present in every European city and honestly - they bore me to death. However once we got there we found few places that are definitely worth visiting and here they are!   &lt;/p&gt;
&lt;p&gt;&lt;em&gt;One place I don't mention that might be worth visiting is Copernicus Science Center. The reason why I don't think it's worth mentioning that it's always full of kids and unless you spend a long time in warsaw to find one day that isn't - it's not worth the headache.&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;University Library&lt;/h4&gt;
&lt;p&gt;&lt;img alt="warsaw library" src="https://media-cdn.tripadvisor.com/media/photo-o/0d/07/2c/13/ogrod-zloty.jpg"&gt;&lt;br&gt;
Library? But we're on vacation! &lt;br&gt;
Weirdly enough it was probably my favourite place in Warsaw. The main attraction was not the library itself, but what's on top of it! The roof of the library is a beautiful garden with all sorts of growth and shapes that create this unique and cosy atmosphere. &lt;br&gt;
There were very few people and the weather wasn't that bad. It's near the river so it can get a bit windy, so pack up a scarf!&lt;/p&gt;
&lt;h4&gt;Technology Museum and Palace of Culture and Science&lt;/h4&gt;
&lt;p&gt;&lt;img alt="Place of Culture and Science image" src="https://granitosaurus.github.io/images/poland_palace.jpg" height=500&gt;&lt;br&gt;
Palace of Culture and Science was gifted to Poland by Russia after WW2. It's a really beautiful building that since in the very center of Warsaw.&lt;br&gt;
Aside of being pretty it also hosts a pretty cool Technology museum inside of it.It contains exhibits ranging from old motorcycles to nintendo games and it's really fun!&lt;br&gt;
Few of the highlights: Space technology exhibit, video games, old vehicles (from bikes to planes)  &lt;/p&gt;
&lt;h2&gt;Pycon PL&lt;/h2&gt;
&lt;p&gt;&lt;img alt="pyconpl 2016" src="https://granitosaurus.github.io/images/pyconpl.png"&gt;&lt;/p&gt;
&lt;p&gt;We got there in the morning of Thursday, the first day of the conference. My girlfriend attended &lt;strong&gt;Pyladies&lt;/strong&gt; workshop while I checked us in. I don't think she enjoyed it as much as I thought she would, but it certainly piqued her interest in programming, so it wasn't bad!  &lt;/p&gt;
&lt;p&gt;The hotel is huge - it supports over 1600 guests and takes a bit under 5 minutes just to go from one end of it to the other. The cafeteria was great and served a sizeable selection of dishes for breakfast, lunch and dinner. As a vegetarian I only felt left out for one lunch where everything seemed to contain meat which means I ate a full plate of roasted potatoes - just like home!  &lt;/p&gt;
&lt;p&gt;The first few talks were half interesting and half boring. I feel like with many of the talks tend to be longer than they actually need to and some people tend to dig into details a bit too much - the talks in this pycon were not an exception.&lt;br&gt;
I think a lot of the presenters miss the point that the talk you are giving should &lt;strong&gt;pique the interest of the listener or tell a story&lt;/strong&gt; rather than try sum up a framework or some technique in 10 slides.&lt;br&gt;
For this reason, I enjoyed the lightning talks the most though that remains to be true for every conference I've been to.&lt;/p&gt;
&lt;p&gt;During the lunch time I met a Lithuanian which was really surprising. Not only python isn't huge in Lithuania but when I was purchasing the tickets one of the hosts mentioned that I'd be the first and only person from Lithuania to attend PyconPL. I'm glad that it turned out not being the case because Lithuania really needs more Python! (or anything that is not php for that matter :D)&lt;/p&gt;
&lt;h3&gt;Meeting Scrapinghubbers&lt;/h3&gt;
&lt;p&gt;This year scrapinghub wasn't sponsoring the conference thus we didn't have a booth. However there were 3 other scrapinghubbers present in the conference other than myself. We chatted and played board games together and I can firmly say that in the two years that I've spent working in Scrapinghub I haven't met a single dislikeable person there and this conference solidified this experience even more!  &lt;/p&gt;
&lt;p&gt;Shoutout to Pawel and two Michals from scrapinghub who made this conference even more fun than it could have been!&lt;/p&gt;
&lt;h3&gt;Board and Retro Games&lt;/h3&gt;
&lt;p&gt;Every evening board game event has been held in one of the conference rooms and that's probably where the majority of the conference was spent. There was a board game rental company that provided the conference with some board games as well as some people bringing their own. We brought Exploding Kittens, Loot Letter and Coup. Exploding Kittens by far received the most attention, though the other two games weren't far behind too.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="polish Mysterium" src="https://granitosaurus.github.io/images/polish_mysterium.jpg"&gt;&lt;br&gt;
We didn't get a chance to play any board games that we haven't touched previously with the exception of &lt;strong&gt;Mysterium&lt;/strong&gt;! Or at least Polish version of it, which is the original version of the game and by some considered to be superior. It's a brilliant coop game where one player is a ghost who was hanged for a murder he did not commit and has gives hints to the other players of who was the real murderer! Some people describe it as reverse Dix It which in a way it is, but in my opinion, much more fun and engaging.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Donkey Konga for gamecube" src="http://media.ign.com/games/image/object/572/572741/Donkey-Konga-1_Game-and-Bongos_Cube_US_ESRB.jpg"&gt;&lt;br&gt;
Another cool piece of entertainment was retro computer games, a full room of them! They had various consoles and computers ranging from atari to windows 95 Worms Armageddon machines. There were open and running through the whole day and you could play something in-between the talks or after having lunch. My personal favorite was Donkey Konga - a party, rhythm game for GameCube. It's like guitar hero but instead of a guitars, players use a set of bongo drums which create a hilarious and often silly atmosphere!&lt;/p&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;p&gt;Initially we didn't find much to do when we did research about Warsaw, however once we got there we got pleasantly surprised by the city and what it offered!  The city is big and beautiful. The center is structured in nice blocks that are easy to traverse and navigate. Every block being full of various small shops, cafÃ©s or restaurants. And even though there were indeed only few experience places we enjoyed them greatly!&lt;br&gt;
Pycon was a blast too! The educational opportunities weren't that great (the talks, workshops etc.) but the board games and leisure activities were more than enough to compensate!  &lt;/p&gt;
&lt;p&gt;Will definitely consider going next year! &lt;br&gt;
Only regret was not taking more luggage.&lt;/p&gt;</content><category term="pycon"></category><category term="python"></category><category term="poland"></category><category term="travel"></category><category term="warsaw"></category></entry><entry><title>How to parse complicated json trees.</title><link href="https://granitosaurus.github.io/crawling-json.html" rel="alternate"></link><published>2016-10-10T00:00:00+02:00</published><updated>2016-10-10T00:00:00+02:00</updated><author><name>Bernardas AliÅ¡auskas</name></author><id>tag:granitosaurus.github.io,2016-10-10:/crawling-json.html</id><summary type="html">&lt;p&gt;Often when web-crawling you can find access to website's api which provides direct JSON of a product, however it's not always so easy to find what you need in what could be a multi-layer mess of a json.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Often when web-crawling you can find access to website's api which provides direct JSON of a product, however it's not always so easy to find what you need in what could be a multi-layer mess of a json.&lt;/p&gt;
&lt;p&gt;In this blog-post I'll cover few tools and ways to deal with really ugly json trees that you probably don't want to iterate through manually using dictionary key indices.&lt;br&gt;
&lt;strong&gt;If you don't care about the research you can just skip to the &lt;a href="#right"&gt;right tool&lt;/a&gt; and &lt;a href="#solving"&gt;solving of the real life case&lt;/a&gt; sections at the end&lt;/strong&gt;.&lt;/p&gt;
&lt;h1&gt;Cause&lt;/h1&gt;
&lt;p&gt;Often websites, especially the ones that sell various products tend to overcomplicate their apis by stacking everything in one huge json tree that is at least 10 layers deep and is impossible to understand for an outsider or maybe even other developers in the company.&lt;/p&gt;
&lt;p&gt;In this case we'll take a look at small examples of &lt;a href="http://ah.nl"&gt;http://ah.nl&lt;/a&gt; responses and how can we deal with them without spending hours trying to reverse engineer the whole process.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example info&lt;/strong&gt;:&lt;br&gt;
Product url: &lt;a href="http://www.ah.nl/producten/product/wi166580/maggi-opkikker-rundvlees"&gt;http://www.ah.nl/producten/product/wi166580/maggi-opkikker-rundvlees&lt;/a&gt;&lt;br&gt;
Product api response: &lt;a href="https://ptpb.pw/aZ_S"&gt;https://ptpb.pw/aZ_S&lt;/a&gt;&lt;br&gt;
If you put this response through some json visual tool like &lt;a href="http://jsonviewer.stack.hu/"&gt;http://jsonviewer.stack.hu/&lt;/a&gt; you'll notice what a huge mess it is: &lt;/p&gt;
&lt;p&gt;&lt;img alt="example json view" src="https://granitosaurus.github.io/images/json-crawling.png"&gt;&lt;/p&gt;
&lt;p&gt;Multiple layers, multiple elements, list in a dict in a list in a dict and to parse that you'd end up doing something like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;body&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;items&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;_embedded&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;lanes&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;_embedded&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;items&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And that's just half-way through the tree. For example to find the sku you'd have to use something like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sku = data[&amp;#39;_embedded&amp;#39;][&amp;#39;lanes&amp;#39;][4][&amp;#39;_embedded&amp;#39;][&amp;#39;items&amp;#39;][0][&amp;#39;_embedded&amp;#39;][&amp;#39;product&amp;#39;][&amp;#39;id&amp;#39;]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that's with hard-coding of list indices which are very likely to change for every product, so on top of that ugly line above you'd have to use multiple list comprehensions to find the correct list item from the &lt;code&gt;lanes&lt;/code&gt; or &lt;code&gt;items&lt;/code&gt; lists.  This is bad, ugly, unreliable and extremely painful to work with.&lt;/p&gt;
&lt;h1&gt;Tools to Solve This&lt;/h1&gt;
&lt;p&gt;There are several ways this can be approaches and let me spoil it for you, majority of them are bad, so we'll start off with those.&lt;/p&gt;
&lt;p&gt;To demonstrate these tools better we'll be parsing this simple json:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data = &amp;quot;&amp;quot;&amp;quot;{
    &amp;quot;one&amp;quot;: {
        &amp;quot;two&amp;quot;: [{
            &amp;quot;four&amp;quot;: {
                &amp;quot;name&amp;quot;: &amp;quot;four1_name&amp;quot;
            }
        }, {
            &amp;quot;four&amp;quot;: {
                &amp;quot;name&amp;quot;: &amp;quot;four2_name&amp;quot;
            }
        }]
    }
}&amp;quot;&amp;quot;&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All examples below are also available on iPython notebook if you want to mess around with them yourself &lt;a href="https://granitosaurus.github.io/data/crawling-json_examples.ipynb"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Wrong: Flattening The Json&lt;/h2&gt;
&lt;p&gt;At first glance this might appear as an obvious solution - just flatten everything to the first level! However this brings out a huge issue with keys. Because every key has to be unique, when flattening the dictionary you need to merge several keys into one to preserve the tree order.
If we were to flatten our &lt;code&gt;data&lt;/code&gt;, it would end up looking like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data = &amp;quot;&amp;quot;&amp;quot;{
    &amp;quot;one_two_four1_name&amp;quot;: &amp;quot;four1_name&amp;quot;,
    &amp;quot;one_two_four2_name&amp;quot;: &amp;quot;four2_name&amp;quot;,
    }&amp;quot;&amp;quot;&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In a way you might think it looks nice, but the truth is that it's really unpredictable and hard to parse in a more complex context, since you can only select individual values. This might be useful for some edge cases where you only need 1 field the json tree is only two or tree levels deep, but otherwise it's not worth bothering with.&lt;/p&gt;
&lt;h2&gt;Wrong: Jmespath, JSONPath and JSONiq etc.&lt;/h2&gt;
&lt;p&gt;These few libraries in a way designed specifically to solve this issue. It seems that json is notoriously bad when it comes to this issue, so tools like theses are dime a dozen on github and while they are great, they fall short when in comes to web-crawling or similar use cases.   &lt;/p&gt;
&lt;p&gt;However there are two major issues with these tools:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;First one being that some of them like the very &lt;code&gt;Jmespath&lt;/code&gt;'s &lt;strong&gt; expressions root-bound&lt;/strong&gt; which means non-rooted expressions like xpath's &lt;code&gt;//product/name&lt;/code&gt; are not possible. This means that you need to write this ugly chain which is barely different to our dict key indices one:&lt;/p&gt;
&lt;p&gt;root.foo.bar[].foo2.bar2.product.mynode&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The only improvement here is that we can do a bit of recursion by calling &lt;code&gt;[]&lt;/code&gt; for every list element, saving us a few list comprehension calls. And it definitely looks nicer, doesn't it?&lt;br&gt;
It is still bad though since at any point the tree might change and our crawler will break because we are root bound.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The second issue being is that all of them &lt;strong&gt;are extremely bloated&lt;/strong&gt;, to the point where they not only design their own parsing logic but also design their own syntax.   &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When you are crawling a website you already have your own parsing tools to parse the html/xml (like &lt;code&gt;lxml&lt;/code&gt; or &lt;code&gt;parsel&lt;/code&gt;) and anything other would just introduce obvious redundancy and unnecessary complexity. &lt;/p&gt;
&lt;h2&gt;Almost Right: js2xml&lt;/h2&gt;
&lt;p&gt;First I'd like to start off with and give a shout out to a great tool called &lt;code&gt;js2xml&lt;/code&gt; which maintained by Scrapinghub. It pretty much does what it says - converts javascript code to an xml tree and it's &lt;em&gt;almost&lt;/em&gt; the right tool for our issue, almost.&lt;br&gt;
Since json is part of javascript, this means we can use this tool to parse it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;lxml&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;etree&lt;/span&gt;
&lt;span class="c1"&gt;# we need to wrap our data json in variable declaration&lt;/span&gt;
&lt;span class="c1"&gt;# for js2xml to interpret it&lt;/span&gt;
&lt;span class="n"&gt;parsed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;js2xml&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;var foo = &amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;etree&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tostring&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;parsed&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pretty_print&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is the result:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;program&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;var&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;foo&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;object&amp;gt;&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;lt;property&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;one&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;object&amp;gt;&lt;/span&gt;
          &lt;span class="nt"&gt;&amp;lt;property&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;two&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;array&amp;gt;&lt;/span&gt;
              &lt;span class="nt"&gt;&amp;lt;object&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;property&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;four&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                  &lt;span class="nt"&gt;&amp;lt;object&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;property&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                      &lt;span class="nt"&gt;&amp;lt;string&amp;gt;&lt;/span&gt;four1_name&lt;span class="nt"&gt;&amp;lt;/string&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
                  &lt;span class="nt"&gt;&amp;lt;/object&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
              &lt;span class="nt"&gt;&amp;lt;/object&amp;gt;&lt;/span&gt;
              &lt;span class="nt"&gt;&amp;lt;object&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;property&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;four&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                  &lt;span class="nt"&gt;&amp;lt;object&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;property&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                      &lt;span class="nt"&gt;&amp;lt;string&amp;gt;&lt;/span&gt;four2_name&lt;span class="nt"&gt;&amp;lt;/string&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
                  &lt;span class="nt"&gt;&amp;lt;/object&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
              &lt;span class="nt"&gt;&amp;lt;/object&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/array&amp;gt;&lt;/span&gt;
          &lt;span class="nt"&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/object&amp;gt;&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/object&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;/var&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/program&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As you can see it works and could probably be parsed with xpath. It's really ugly and if we were to write an xpath for it, it would be unnecessary complicated and long, but it would work! &lt;br&gt;
If you are already using it to parse javascript somewhere you might just go with it to reduce dependencies if you wish so.&lt;/p&gt;
&lt;h1 id="right"&gt;Right: Converting json to xml and Parsing It With xpath&lt;/h1&gt;
&lt;p&gt;I found two tools and either one of them combined with either &lt;a href="http://lxml.de/"&gt;&lt;code&gt;lxml&lt;/code&gt;&lt;/a&gt; or &lt;a href="https://github.com/scrapy/parsel"&gt;&lt;code&gt;parsel&lt;/code&gt;&lt;/a&gt; selectors create this beautiful, perfect json-crawling combo for your crawler! &lt;/p&gt;
&lt;p&gt;For unaware &lt;code&gt;lxml&lt;/code&gt; is a really great tool for parsing xml and html while &lt;code&gt;parsel&lt;/code&gt; is built on top of it to make it even greater, so I highly recommend checking it out!
Fun fact - it's also used by &lt;a href="https://github.com/scrapy/scrapy"&gt;scrapy&lt;/a&gt; and that's where it originated.&lt;/p&gt;
&lt;p&gt;Getting back to the point, the two tools that are pretty much alternative to each other are &lt;a href="https://github.com/quandyfactory/dicttoxml"&gt;&lt;code&gt;dicttoxml&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://github.com/delfick/python-dict2xml"&gt;&lt;code&gt;dict2xml&lt;/code&gt;&lt;/a&gt;. They are essentially the same thing but I thought I'd mention both since I'm not sure which one is better and requires the recognition. &lt;br&gt;
For sake of being brief I'll show off &lt;code&gt;dicttoxml&lt;/code&gt; + &lt;code&gt;parsel&lt;/code&gt; only:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;dicttoxml&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;dicttoxml&lt;/span&gt;
&lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dicttoxml&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;attr_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# the tree we get:&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;one&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;two&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;four&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
          &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;four1_name&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;four&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;four&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
          &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;four2_name&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;four&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;two&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;one&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we can parse this tree using &lt;code&gt;parsel.Selector&lt;/code&gt; and xpath:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;parsel&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Selector&lt;/span&gt;
&lt;span class="n"&gt;sel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Selector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;# and get the names with&lt;/span&gt;
&lt;span class="n"&gt;sel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;//name/text()&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;# [&amp;#39;four1_name&amp;#39;, &amp;#39;four2_name&amp;#39;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Pretty mind blowing how we solved this mess with one 300 loc big package from pypi and one short xpath.&lt;/p&gt;
&lt;h1 id="solving"&gt;Solving Our Example&lt;/h1&gt;
&lt;p&gt;Now that we have chosen a tool let's see how well it works on a real life example we got ourselves at the beginning of this blog: &lt;a href="http://www.ah.nl/producten/product/wi166580/maggi-opkikker-rundvlees"&gt;http://www.ah.nl/producten/product/wi166580/maggi-opkikker-rundvlees&lt;/a&gt;   &lt;/p&gt;
&lt;p&gt;I'm going to spoil you the joy of reverse engineering the products api and tell you the api url in this case is: 
&lt;code&gt;'http://www.ah.nl/service/rest/delegate?url=/producten/product/wi166580/x'&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Lets assume we already have the page source in &lt;code&gt;body&lt;/code&gt; variable and dive in:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;dicttoxml&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;dicttoxml&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;parsel&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Selector&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;

&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;body&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Selector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dicttoxml&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attr_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;# now we can find things very easily!&lt;/span&gt;
&lt;span class="c1"&gt;# sku:&lt;/span&gt;
&lt;span class="n"&gt;sel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;//product/id/text()&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;# [u&amp;#39;wi166580&amp;#39;]&lt;/span&gt;
&lt;span class="c1"&gt;# price:&lt;/span&gt;
&lt;span class="n"&gt;sel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;//product//pricelabel/now/text()&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;# [u&amp;#39;0.82&amp;#39;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Mission accomplished! We managed to parse multi-layer monster with very few, simple xpaths and a small package from pipy!&lt;br&gt;
Personally I wish I started doing this earlier because iterating through monsters like this one key at the time is extremely tedious and it breaks every time the website decides to update something. &lt;br&gt;
Hopefully this write up can save someone few hours and an early balding. :D&lt;/p&gt;</content><category term="python"></category><category term="crawling"></category><category term="json"></category><category term="scrapy"></category><category term="parsel"></category><category term="dicttoxml"></category></entry><entry><title>Going to Pycon Poland!</title><link href="https://granitosaurus.github.io/pycon-pl.html" rel="alternate"></link><published>2016-10-10T00:00:00+02:00</published><updated>2016-10-10T00:00:00+02:00</updated><author><name>Bernardas AliÅ¡auskas</name></author><id>tag:granitosaurus.github.io,2016-10-10:/pycon-pl.html</id><summary type="html">&lt;p&gt;Going to Pycon PL and checking out Warsaw!&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last year in Euro-Python 2015 someone from PyconPL had a lightning talk about PyconPL and since that moment I was sold. However I missed it by few days. This year however, I'm going and I'm taking a short vacation to explore Warsaw too!&lt;/p&gt;
&lt;p&gt;There's a bunch of info about the conference on the &lt;a href="https://pl.pycon.org/2016/about_en.html"&gt;official page&lt;/a&gt; and I don't want to be redundant, but the venue looks awesome and in overall the event looks pretty huge. Primarily I just wanted to share how much money do you need to attend something like this, how do you get there and lastly whether it is worth it.   &lt;/p&gt;
&lt;h1&gt;The route&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Trip route from Tartu to Warsaw" src="https://granitosaurus.github.io/images/pycon-pl-travel.png"&gt;   &lt;/p&gt;
&lt;p&gt;So we're taking a bus from Tartu -&amp;gt; Riga which is really the most tedious part of this trip. As you can see in the image the trip almost takes &lt;strong&gt;4 hours&lt;/strong&gt; and the bus leaves early and often is packed full. We'll spend two hours in Riga's airport waiting for our flight, which I really don't mind since Riga's airport is really nice. And to finish it off we'll take a &lt;strong&gt;1.25&lt;/strong&gt; hour long flight to Warsaw itself. I love flying, more accurately I like take offs and landings so having such short flights, where majority of the time will be the take off and the landing, sounds great!&lt;br&gt;
In conclusion, we leave at 7:00 and we should be in Warsaw at 14:35 (warsaw's time). So this ends up being &lt;strong&gt;8.5 hours for 900km&lt;/strong&gt; which really doesn't have a good hour/km ratio per se but considering the down-times and the location it really isn't bad at all! &lt;br&gt;
Lastly the conference organizes a bus that will take us from Warsaw to Ossa village, which is few kilometers away from Warsaw and there the conference itself will be held. &lt;/p&gt;
&lt;h1&gt;The Cost&lt;/h1&gt;
&lt;h3&gt;Conference&lt;/h3&gt;
&lt;p&gt;Since I was a bit late to register and missed the early bird prices, I had to drop 211â¬ per person (422â¬ for two people) for 4 days of the conference, including food and accommodation. This might seem like a lot but compared to other conferences is really little. &lt;br&gt;
I actually chatted with one of the hosts a bit and he mentioned that pretty much the whole fee goes to the hotel that is hosting the conference, after visiting the website I can understand that since it advertises the rooms at 90â¬ a night the conference fee seems to be very reasonable indeed!&lt;/p&gt;
&lt;h3&gt;Travel&lt;/h3&gt;
&lt;p&gt;The plane tickets from Riga to Warsaw and back ended up being 62â¬ per person(125â¬ for two) which is slightly above from the best I could find. At one point I got 42â¬ deals pop up but the payment didn't go through and the next day it popped to 62â¬. I know airline websites are really fishy when it comes to pricing, storing profiles and cookies to jack up the price whenever they see fit but I'm certain this was just an unfortunate coincidence.&lt;br&gt;
The bus to Riga from Tartu ended up being 30â¬ per person (60â¬ in total) both ways.&lt;/p&gt;
&lt;p&gt;So &lt;strong&gt;total ended up being 303â¬ per person&lt;/strong&gt; which is pretty cheap for a conference 906km away!&lt;br&gt;
This doesn't include any traveling expenses which I'll be sure to calculated and include in aftermath blogpost!&lt;/p&gt;
&lt;p&gt;The last python conference I went to was EuroPython 2015 and it was super fun, mostly because I got to meet a bunch of coworkers from Scrapinghub, I hope PyconPL can live up to the hype and I'll be sure to post about it either way.&lt;/p&gt;</content><category term="pycon"></category><category term="python"></category><category term="poland"></category><category term="travel"></category></entry><entry><title>First post. Hello Pelican!</title><link href="https://granitosaurus.github.io/installing-pelican.html" rel="alternate"></link><published>2016-10-09T00:00:00+02:00</published><updated>2016-10-09T00:00:00+02:00</updated><author><name>Bernardas AliÅ¡auskas</name></author><id>tag:granitosaurus.github.io,2016-10-09:/installing-pelican.html</id><summary type="html">&lt;p&gt;Starting up the blog with Python and Pelican static blog generator!&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've decided to start a blog after Python package called Pelican caught my eye.&lt;br&gt;
Pelican is a tool to generate a static blog from reStructuredText or Markdown input files. And most importantly it looks to be really fun, full python with jinja2 templating, which means it's fully extendable, configurable and modifiable as it's under GPL license.&lt;/p&gt;
&lt;h3&gt;Installing Pelican&lt;/h3&gt;
&lt;p&gt;&lt;img alt="Pelicans are cool" src="https://granitosaurus.github.io/images/pelican-bird.jpg"&gt;&lt;br&gt;
The setup for &lt;code&gt;Pelican&lt;/code&gt; is pretty straightforward just run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;~&amp;gt; pip install pelican  &lt;span class="c1"&gt;# Installing Pelican package for python&lt;/span&gt;
~&amp;gt; mdir blog &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;cd&lt;/span&gt; blog  &lt;span class="c1"&gt;# Create and jump into your blog directory!&lt;/span&gt;
~/blog/&amp;gt; pelican-quickstart
    ... &lt;span class="c1"&gt;#answer some simple questions here&lt;/span&gt;
~/blog/&amp;gt; vim content/first-page.md
    ... &lt;span class="c1"&gt;#write your blog here in simple markdown&lt;/span&gt;
~/blog/&amp;gt; pelican content  &lt;span class="c1"&gt;# regenerate website&lt;/span&gt;
~/blog/&amp;gt; &lt;span class="nb"&gt;cd&lt;/span&gt; output
~/blog/output&amp;gt; python -m pelican.server  &lt;span class="c1"&gt;# run pelican server to test locally&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now connect to &lt;code&gt;http://localhost:8000&lt;/code&gt; and there you go!&lt;br&gt;
You can check &lt;a href="http://docs.getpelican.com/en/latest/content.html#articles-and-pages"&gt;here&lt;/a&gt; for how to template your message how to format your blog entry.&lt;/p&gt;
&lt;h3&gt;Vim markdown highlight for .md files&lt;/h3&gt;
&lt;p&gt;While going through the installation I've noticed that markdown doesn't have highlighting in vim which was peculiar. I found &lt;a href="http://superuser.com/questions/701496/no-syntax-highlight-on-md-files"&gt;this post which describes a simple fix&lt;/a&gt;.&lt;br&gt;
Simply create directories and file: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;~/.vim/ftdetect/markdown.vim
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;with content: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;au BufNewFile,BufRead *.md  setf markdown
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Theming Pelican&lt;/h3&gt;
&lt;p&gt;The default Pelican theme is pretty great however I stumbled on &lt;a href="https://github.com/alexandrevicenzi/Flex"&gt;flex-theme&lt;/a&gt; on &lt;a href="https://github.com/getpelican/pelican-themes"&gt;pelican theme repo&lt;/a&gt; on github. So that's my choice for now, but I'd like to touch up the color scheme a bit. Check out &lt;a href="http://docs.getpelican.com/en/stable/pelican-themes.html"&gt;&lt;code&gt;pelican-themes&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Configuring Pelican&lt;/h3&gt;
&lt;p&gt;A lot of bells and whistles come straight out of the box with the pelican and your theme. For example to setup Disqus commnets all I had to do is add &lt;code&gt;DISQUS_SITENAME = "granitosaurus"&lt;/code&gt; where &lt;code&gt;granitosaurus&lt;/code&gt; is my registered name of my disqus account.&lt;/p&gt;
&lt;h3&gt;Publishing Pelican&lt;/h3&gt;
&lt;p&gt;Since Pelican generates a static webpage you can use anything to publish it. I decided to use &lt;a href="http://docs.getpelican.com/en/stable/tips.html#user-pages"&gt;github user pages&lt;/a&gt; which is a bit more complicated than the docs make it out to be. For user pages I like to keep the whole source code in branch &lt;code&gt;source&lt;/code&gt; and keep the generated output in &lt;code&gt;master&lt;/code&gt; as per github's user pages rule. Then use &lt;code&gt;ghp-import&lt;/code&gt; to automatically update master code with the most recent  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt; &lt;span class="n"&gt;git&lt;/span&gt; &lt;span class="n"&gt;checkout&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="n"&gt;source&lt;/span&gt;
&lt;span class="err"&gt;$&lt;/span&gt; &lt;span class="n"&gt;pelican&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="n"&gt;publishconf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;span class="err"&gt;$&lt;/span&gt; &lt;span class="n"&gt;ghp&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;output&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="n"&gt;master&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The above will make source branch, generate blog and push the output to &lt;code&gt;master&lt;/code&gt; so it's viewable at https://username.github.io &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; The most important bit is to set &lt;code&gt;SITEURL&lt;/code&gt; in your &lt;code&gt;publishconf.py&lt;/code&gt; to &lt;code&gt;https://username.github.io&lt;/code&gt; make sure it's &lt;strong&gt;HTTPS&lt;/strong&gt; since default SITEURL generated by pelican is http and github pages requires https. This took me an hour of messing around to finally figure out.&lt;/p&gt;
&lt;h3&gt;Wrap Up&lt;/h3&gt;
&lt;p&gt;So far Pelican took quite a bit of work to get things going. It looks quite simple but there's a bunch of little quirks that are really hard to debug. It's not as easy as starting up a wordpress blog but it's quite fun and it seems to be really flexible. &lt;br&gt;
Let's see if it pays off! &lt;/p&gt;
&lt;p&gt;Checkout the source for more at https://github.com/Granitas/granitas.github.io/tree/source&lt;/p&gt;</content><category term="pelican"></category><category term="python"></category><category term="blog"></category></entry></feed>